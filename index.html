<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta name="description" content="DESCRIPTION META TAG" />
    <meta property="og:title" content="SOCIAL MEDIA TITLE TAG" />
    <meta
      property="og:description"
      content="SOCIAL MEDIA DESCRIPTION TAG TAG"
    />
    <meta property="og:url" content="URL OF THE WEBSITE" />
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <meta property="og:image" content="static/image/your_banner_image.png" />
    <meta property="og:image:width" content="1200" />
    <meta property="og:image:height" content="630" />

    <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG" />
    <meta
      name="twitter:description"
      content="TWITTER BANNER DESCRIPTION META TAG"
    />
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <meta
      name="twitter:image"
      content="static/images/your_twitter_banner_image.png"
    />
    <meta name="twitter:card" content="summary_large_image" />
    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>
      Multimodal Methods for Analyzing Learning and Training Environments: A
      Systematic Literature Review
    </title>
    <link rel="icon" type="image/x-icon" href="static/images/favicon.ico" />
    <link
      href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
      rel="stylesheet"
    />

    <link rel="stylesheet" href="static/css/bulma.min.css" />
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css" />
    <link rel="stylesheet" href="static/css/bulma-slider.min.css" />
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css" />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"
    />
    <link rel="stylesheet" href="static/css/index.css" />

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>
  </head>
  <body>
    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">
                Multimodal Methods for Analyzing Learning and Training
                Environments: A Systematic Literature Review
              </h1>
              <div class="is-size-5 publication-authors">
                <!-- Paper authors -->
                <span class="author-block">
                  <a href="https://www.claytoncohn.com" target="_blank"
                    >Clayton Cohn</a
                  >,
                </span>
                <span class="author-block">
                  <a href="https://edavalosanaya.github.io" target="_blank"
                    >Eduardo Davalos</a
                  >,
                </span>
                <span class="author-block">
                  <a href="https://www.vatral.net" target="_blank"
                    >Caleb Vatral</a
                  >,
                </span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=6QmCCGEAAAAJ&hl=en" target="_blank"
                    >Joyce Horn Fonteles</a
                  >,
                </span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=6QmCCGEAAAAJ&hl=en" target="_blank"
                    >Hanchen David Wang</a
                  >,
                </span>
                <span class="author-block">
                  <a href="https://meiyima.github.io" target="_blank"
                    >Meiyi Ma</a
                  >,
                </span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=-m5wrTkAAAAJ&hl=en" target="_blank"
                    >Gautam Biswas</a
                  >
                </span>
              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block"
                  >Vanderbilt University</span
                >
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <!-- PDF link -->
                  <span class="link-block">
                    <a
                      href="https://github.com/oele-isis-vanderbilt/MMLTE_SLR/blob/master/static/pdfs/Examining_Multimodal_Methods_for_Analyzing_Learning_and_Training_Environments__A_Systematic_Literature_Review__ACM_Computing_Surveys_.pdf"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a
                      href="https://github.com/oele-isis-vanderbilt/MMLTE_SLR"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span>

                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Teaser Image-->
    <section class="hero teaser">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <img src="static/images/20240502_architecture.png" alt="MY ALT TEXT" />
          <h2 class="subtitle has-text-justified">
            The "Multimodal Learning and Training Environments Literature Review" framework decomposes the multimodal learning and training analytics process into four primary components: the learning or training environment, multimodal data, learning analytics methods, and feedback. This framework provides a structured approach to understanding how different modalities and methods are integrated to enhance the analysis of educational and training environments, ultimately aiming to improve learning outcomes through comprehensive data collection and analysis techniques.
          </h2>
        </div>
      </div>
    </section>
    <!-- End teaser video -->

    <!-- Paper Summary -->
    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Summary</h2>
            <div class="content has-text-justified">
              <p>
                This systematic literature review examines the current state of multimodal methods for analyzing learning and training environments. We provide a comprehensive taxonomy and framework that encapsulates recent methodological advances, categorizing multimodal data into five groups: Natural Language, Video, Sensors, Human-Centered, and Environment Logs. Our findings reveal that integrating multiple modalities offers a more holistic understanding of learner behaviors and outcomes, often uncovering patterns missed by single-modality data. Despite the promise of multimodal methods, significant challenges remain, including data integration complexity, quality assurance, and scalability issues. We also identify critical research gaps, such as the need for standardized approaches and more studies on physical and blended learning environments. This review highlights the potential of multimodal analytics to enhance educational experiences and provides a roadmap for future research, encouraging further exploration and development in this evolving field.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End paper summary -->

    <!-- Teaser Image-->
    <section class="Fusion Scheme">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <img src="static/images/Fusion Diagram.png" alt="MY ALT TEXT" />
          <h2 class="subtitle has-text-justified">
            Multimodal data fusion scheme illustrating the integration of various data sources at different stages of processing relative to the observability line. Early fusion combines raw, observable features; mid fusion integrates moderately processed, still observable features; and late fusion merges fully processed, inferred features. This scheme emphasizes the conceptual distinction between directly observable data and inferred annotations, facilitating a nuanced approach to multimodal data integration and analysis. We expanded the prior literature's taxonomy by introducing this fusion scheme, which provides a more detailed classification and addresses ambiguities in defining raw versus processed features. This enhancement allows for a clearer identification of the processes involved in multimodal data fusion and better supports the development of robust multimodal learning and training analytics.
          </h2>
        </div>
      </div>
    </section>
    <!-- End teaser video -->

    <!-- Image carousel -->
    <section class="hero is-small">
      <div class="hero-body">
        <div class="container">
          <div id="results-carousel" class="carousel results-carousel">
            <div class="item">
              <!-- Your image here -->
              <img src="static/images/statistical_imgs/data_collection_mediums_2.png" alt="MY ALT TEXT"/>
              <h2 class="subtitle has-text-centered">
                Data collection mediums distributions.
              </h2>
            </div>
            <div class="item">
              <!-- Your image here -->
              <img src="static/images/statistical_imgs/modalities_counts_in2.png" alt="MY ALT TEXT"/>
              <h2 class="subtitle has-text-centered">
                Frequency counts for the number of papers in our corpus containing each modality.
              </h2>
            </div>
            <div class="item">
              <!-- Your image here -->
              <img src="static/images/statistical_imgs/number of modalities per count of papers.png" alt="MY ALT TEXT"/>
              <h2 class="subtitle has-text-centered">
              The number of modalities used per paper, i.e., how mnay papers (y-axis) used n modalities (x-axis).
            </h2>
            </div>
            <div class="item">
              <!-- Your image here -->
              <img src="static/images/statistical_imgs/fusion_dist_pie_chart_donut_16.png" alt="MY ALT TEXT"/>
              <h2 class="subtitle has-text-centered">
                Distribution of Fusion Types.
              </h2>
            </div>
            <div class="item">
              <!-- Your image here -->
              <img src="static/images/statistical_imgs/model_based_model_free_pie_chart.png" alt="MY ALT TEXT"/>
              <h2 class="subtitle has-text-centered">
                Analysis approaches percentage distribution.
              </h2>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End image carousel -->

    <!-- Paper Conclusions -->
    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Conclusion</h2>
            <div class="content has-text-justified">
              <h3 class="title is-4">Challenges</h3>
              <p>
                The review identifies several challenges in the field of multimodal learning and training environments. Key challenges include the complexity of integrating diverse data streams, ensuring data quality and privacy, and addressing the variability in data collection environments. Limitations are noted in the scalability of certain methods and the need for more robust, standardized approaches to data fusion and analysis.
              </p>
              <h3 class="title is-4">Future Research Directions</h3>
              <p>
                The research also highlights significant gaps, such as the underrepresentation of certain modalities and the need for more studies focused on physical and blended learning environments. Future work should aim to bridge these gaps by developing more scalable, standardized methodologies and exploring new avenues for integrating and analyzing multimodal data. The paper provides a comprehensive roadmap for addressing these challenges and advancing the field, inviting researchers to delve deeper into specific areas of interest.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End Paper Conclusions -->

    <!-- Teaser Image-->
    <section class="citation graph prunning">
      <div class="container is-max-desktop">
        <div class="hero-body">

          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <h2 class="title is-3">Corpus Distillation</h2>
            </div>
          </div>

          <img src="static/images/cgp.png" alt="MY ALT TEXT" />
          <div class="content has-text-justified">
            <p>
              The corpus distillation process involved a novel approach called citation graph pruning combined with a methodical qualitative review. Citation graph pruning utilized a directed citation graph to iteratively remove papers with minimal connections to the corpus, thereby reducing the initial set from 4,200 to 1,063 papers. Following this, a systematic qualitative process was employed, which included reviewing titles, abstracts, and full texts. This rigorous method further refined the corpus by excluding irrelevant or less pertinent papers, ultimately distilling the set to 73 high-quality papers that were comprehensively analyzed in the review.
            </p>
          </div>
        </div>
      </div>
    </section>
    <!-- End teaser video -->


    <!--BibTex citation -->
    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>BibTex Code Here</code></pre>
      </div>
    </section>
    <!--End BibTex citation -->

    <footer class="footer">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">
              <p>
                This page was built using the
                <a
                  href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                  target="_blank"
                  >Academic Project Page Template</a
                >
                which was adopted from the <a
                  href="https://nerfies.github.io"
                  target="_blank"
                  >Nerfies</a
                > project page. You are free to borrow the of this website, we
                just ask that you link back to this page in the footer. <br />
                This website is licensed under a
                <a
                  rel="license"
                  href="http://creativecommons.org/licenses/by-sa/4.0/"
                  target="_blank"
                  >Creative Commons Attribution-ShareAlike 4.0 International
                  License</a
                >.
              </p>
            </div>
          </div>
        </div>
      </div>
    </footer>

    <!-- Statcounter tracking code -->

    <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->
  </body>
</html>
